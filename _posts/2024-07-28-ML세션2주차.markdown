---
layout: post
title:  "ML세션 2주차"
date:   2024-07-28 20:47:24 +0900
categories: jekyll update
---

**# 혼자 공부하는 머신러닝+딥러닝 Ch. 1, 2**

# Ch.1 나의 첫 머신러닝

## 1-1 인공지능과 머신러닝, 딥러닝

### 인공지능

: 사람처럼 학습히고 추론할 수 있는 기능을 가진 컴퓨터 시스템을 만드는 기술
1. 인공일반지능(강인공지능)
- 사람과 구분하기 어려운 지능을 가진 컴퓨터 시스템
2. 약인공지능
- 특정 분야에서 사람의 일을 도와주는 보조 역할만 가능한 컴퓨터 시스템

### 머신러닝

: 규칙을 일일이 프로그래밍하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야
- 인공지능의 하위 분야 중 '지능'을 구현하기 위한 소프트웨어 담당
- 오픈소스 통계 소프트웨어 R
- 머신러닝 라이브러리 사이킷런(scikit-learn)
    - 파이썬 API 사용
    - 검증된 알고리즘만 포함되어있으므로 안정적이고 성능이 검증됨

### 딥러닝

: 머신러닝 알고리즘 중 인공 신경망을 기반으로 한 방법들을 통칭함
- 딥러닝 라이브러리 텐서플로(TensorFlow) by 구글
- 딥러닝 라이브러리 파이토치(PyTorch) by 페이스북

## 1-2 코랩과 주피터 노트북

### 구글 코랩

: 웹 브라우저에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스, 클라우드 기반의 주피터 노트북 개발 환경

- 노트북: 코랩 파일
- 주피터: 대화식 프로그래밍 환경
- 텍스트 셀 <br>
    <img width="395" alt="image" src="https://github.com/user-attachments/assets/0c188f69-347e-4752-8f5a-3299b776d359">
    <img width="385" alt="image" src="https://github.com/user-attachments/assets/a5404de3-6ec3-4ac1-ba57-939aeb923c55">

## 1-3 마켓과 머신러닝

- 머신러닝은 분류 기준을 스스로 찾아냄

### k-최근접 이웃 알고리즘(K-NN)

```python
# 도미와 빙어 데이터 합치기
length = bream_length+smelt_length
weight = bream_weight+smelt_weight
```

```python
# 데이터를 2차원 리스트로 만들기
fish_data = [[l, w] for l, w in zip(length, weight)]

print(fish_data)
```
- **2차원 리스트**
: 머신러닝 패키지인 사이킷런을 사용하려면 각 특성의 리스트를 세로 방향으로 늘어뜨린 2차원 리스트(리스트의 리스트)를 만들어야함

- `zip()` <br>
: 나열된 리스트에서 원소를 하나씩 꺼내줌
![image](https://github.com/user-attachments/assets/3568f8be-4c22-416b-8cf1-bfb0d01864d8)

<br>

```python
# 정답 데이터 만들기
fish_target = [1]*35 + [0]*14
print(fish_target)
```
- 보통 찾으려는 대상을 1로 놓음 (여기서는 도미가 1)

```python
# KNeighborsClassifier 클래스의 객체 만들기
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()
```
- `KNeighborsClassifier` <br>
: k-최근접 이웃 분류 모델을 만드는 사이킷런 클래스
    - **n_neighbors** 매개변수: 이웃의 개수 지정, 기본값 5
    - **p** 매개변수: 거리 재는 방법 지정, 기본값 2 (1이면 맨해튼 거리, 2이면 유클리디안 거리)
    - **n_jobs** 매개변수: 사용할 CPU 코어 지정, 기본값 1 (-1이면 모든 CPU 코어 사용, 이웃 간의 거리 계산 속도를 높일 수 있지만 fit() 메서드에는 영향x)

```python
# kn 모델 훈련시키기
kn.fit(fish_data, fish_target)
```
- `.fit()` <br>
: kn 객체에 fish_data와 fish_target을 전달하여 도미를 찾기 위한 기준을 학습시킴 -> 훈련

```python
# kn 모델 성능 평가하기(정확도)
kn.score(fish_data, fish_target)
```
- `.score()` <br>
: 0과 1 사이의 값 반환, 1은 모든 데이터를 정확히 맞혔다는 것 의미
    - 정확도 = (정확히 맞친 개수)/(전체 데이터 개수)

```python
# 새로운 데이터
plt.scatter(bream_length, bream_weight)
plt.scatter(smelt_length, smelt_weight)
plt.scatter(30, 600, marker='^')
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```
- KNN은 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용
![image](https://github.com/user-attachments/assets/38ef0a42-2c7d-4492-a7af-1904dd806bde)
    삼각형으로 표시된 새로운 데이터는 도미라고 판단 <br>
    <- 주변에 도미 데이터가 많기 때문에(가장 가까운 직선거리에 어떤 데이터가 있는지)

```python
# 새로운 데이터의 정답 예측하기
kn.predict([[30, 600]])
```
- `.predict()` <br>
: 새로운 데이터의 정답 예측 <br>
    - fit 메서드처럼 리스트의 리스트를 전달해야함 <br>
    - 이 예시에서는 array([1])을 반환하므로 해당 데이터는 도미

```python
# kn 모델의 내부 속성 확인하기
print(kn._fit_X)
print(kn._y)
```
- `._fit_X` <br>
: KNN 모델이 학습한 입력 데이터(특징 행렬, feature matrix)

- `_y`
: KNN 모델이 학습한 출력 데이터(레이블, target vector)

- KNN의 특징
    - KNN에서의 "훈련"은 단순히 학습 데이터를 저장하는 과정으로 학습 데이터 자체가 모델의 일부로 저장되지만 
    - 훈련이 되는 모델에서는 학습 데이터를 직접 저장하기보다는 학습된 매개변수나 모델 구조를 저장함

```python
# 참고 데이터를 49개로 한 kn49 모델
kn49 = KNeighborsClassifier(n_neighbors=49)
```
- `n_neighbors='49'` <br>
: 기본값은 5개인데 49개로 바꿀 경우, 도미가 35개로 다수를 차지하므로 어떤 데이터를 넣어도 무조건 도미로 예측하게 됨

```python
# kn49 모델 성능 평가하기 (정확도)
kn49.fit(fish_data, fish_target)
kn49.score(fish_data, fish_target)
```
>>> 0.7142857142857143 = (도미 개수/전체 개수)

# Ch.2 데이터 다루기

## 2-1 훈련 세트와 테스트 세트

### 머신러닝 알고리즘
- 지도 학습 알고리즘(supervised learning)
    - 훈련 데이터: 입력(input) + 타깃(target)
        -  입력
- 비지도 학습 알고리즘(unsupervised learning)


























