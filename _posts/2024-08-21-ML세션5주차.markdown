---
layout: post
title:  "ML세션 5주차"
date:   2024-08-21 19:37:24 +0800
categories: jekyll update
published: true
---

**# 혼자 공부하는 머신러닝+딥러닝 Ch. 5**

# Ch.5 트리 알고리즘

## **5-1 결정 트리**

### **로지스틱 회귀로 와인 분류하기**

**1. 와인 데이터 불러오기**

```python
import pandas as pd

wine = pd.read_csv('https://bit.ly/wine_csv_data')
wine.head()
```

<img width="160" alt="image" src="https://github.com/user-attachments/assets/590ef23d-7e95-4dc6-95ac-d835658f8898">

**2. 판다스 df를 넘파이 배열로 바꾸기**

```python
data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()
```

**3.훈련 세트와 테스트 세트로 나누기**

```python
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)
```

- `test_size=0.2`: 샘플의 20%만 테스트 세트로 나눔
    - 기본값은 25%

**4. 특성 표준화해서 전처리하기**

```python
from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)

train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)
```

**5. 로지스틱 회귀 모델 훈련하고 성능 평가하기**

```python
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_scaled, train_target)

print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))
```

> 0.7808350971714451
> 0.7776923076923077

&rarr; 과소적합

**6. 결정계수와 절편 출력하기**

```python
print(lr.coef_, lr.intercept_)
```

> [[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]

&rarr; z = 0.51270274 x (알코올 도수) + 1.6733911 x (당도) - 0.68767781 x (pH) + 1.81777902, if z>0 &rarr; 화이트 와인, if z<0 &rarr; 레드 와인
&rarr; 설명하기 어려움
&rarr; 로지스틱 회귀 대신 결정 트리

### **결정 트리**
: 예/아니오에 대한 질문을 이어나가면서 정답을 찾아 학습하는 알고리즘
- 노드: 훈련 데이터의 특성에 대한 테스트 표현 
    - 루트 노드: 맨 위의 노드
    - 리프 노드: 맨 아래의 노드
- 가지: 테스트의 결과 (True/False)를 나타냄
- 예측 클래스: 노드에서 더 많은 샘플이 있는 클래스로 예측

**1. 결정 트리 훈련하고 성능 평가하기**

```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```

> 0.996921300750433
> 0.8592307692307692

&rarr; 과대적합
&rarr; 트리가 제한 없이 자라났기 때문에

- **DecisionTreeClassifier()**
: 결정 트리 분류 클래스
    - `criterion` 매개변수: 불순도 지정
        - 기본값은 'gini'
        - 'entropy'

    - `splitter` 매개변수: 노드 분할하는 전략 선택
        - 기본값은 'best': 정보 이득이 최대가 되도록
        - 'random'이면 임의로 노드 분할
    
    - `max_depth` 매개변수: 트리가 성장할 최대 깊이 지정
        - 기본값은 'None': 리프 노드가 순수하거나 min_smaples_split보다 샘플 개수가 적을 때까지 성장

    - `max_samples_split` 매개변수: 노드를 나누기 위한 최소 샘플 개수
        - 기본값은 2

    - `max_features` 매개변수: 최적의 분할을 위해 탐색할 특성의 개수 지정
        - 기본값은 'None'

**2. 결정 트리 그림으로 나타내기**

```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()
```
<img width="604" alt="image" src="https://github.com/user-attachments/assets/46169ee9-9628-431b-9c89-9b9e4db7f4c8">

<img width="164" alt="image" src="https://github.com/user-attachments/assets/7206dc84-39d6-4d2a-ae7e-a7a4ff536a25">

**3. 결정 트리의 루트 노드와 아래의 노드 그리기**

```python
plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```

- **plot_tree()**
: 결정 트리 모델 시각화
    - `max_depth=1`: 루트 노드와 아래의 노드 1개를 그림
    - `filled=True`: 클래스에 맞게 색 칠하기
        - value = []의 왼쪽이 음성 클래스, 오른쪽이 양성 클래스
        - 음성 클래스가 많으면 붉은색, 양성 클래스가 많으면 푸른색
        - 특정 클래스의 비율이 높아지면 점점 진한 색
    - `feature_names=['alcohol', 'sugar', 'pH']`: 특성의 이름 전달

### **지니 불순도(gini)**

- DecisionTreeClassifier()의 `criterion`매개변수의 기본값이 'gini'
    - `critierion` 매개변수: 노드에서 데이터를 분할할 기준을 정하는 것
    - `criterion='entropy'`
        : 엔트로피 불순도 = - 음성 클래스 비율 x log_2(음성 클래스 비율) - 양성 클래스 비율 x log_2(양성 클래스 비율)
: *지니 불순도 = 1 - (음성 클래스 비율^2 +양성 클래스 비율^2)*

- 최악의 지니 불순도 = 0.5
    &rarr; 노드의 두 클래스의 비율이 1/2씩일 경우
    &rarr; 1 - ((50/100)^2 + (50/100)^2) = 0.5
    <img width="284" alt="image" src="https://github.com/user-attachments/assets/4cd00de7-47e1-4bd1-8cc9-eff96ae20644">

- **정보 이득**
: 부모 노드와 자식 노드의 불순도 차이
    - *부모의 불순도 - (왼쪽 노드 샘플 수/부모의 샘플 수) x 왼쪽 노드 불순도 - (오른쪽 노드 샘플 수/부모의 샘플 수) x 오른쪽 노드 불순도*
    - 결정 트리 모델은 부모 노드와 자식 노드의 불순도 차이가 가능한 크도록 트리를 성장시킴

### **가지치기**

: 루트 노드 아래로 몇개의 노드까지만 성장하게 함
&rarr; 과대적합 방지


**1. 가지쳐서 결정 트리 모델 훈련하고 성능 평가하기**

```python
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
```

> 0.8454877814123533
> 0.8415384615384616

&rarr; 훈련 세트의 점수는 낮아졌지만, 테스트 세트 점수는 그대로

**2. 가지친 결정 트리 모델 그리기**

```python
plt.figure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```

<img width="664" alt="image" src="https://github.com/user-attachments/assets/5dcddd9d-b481-4fc2-b994-f688bf5abb20">

&rarr; but 특성값이 표준점수로 바뀐 상태이기 때문에 이해하기 어려움
ex) sugar <= -0.239

### **결정 트리에서의 전처리**

: 결정 트리에서 가지를 나누는 기준은 불순도
&rarr; 불순도는 클래스별 비율로 계산하기 때문에 특성값의 스케일과 무관
&rarr; 표준화 전처리할 필요x

**1. 전처리하지 않은 훈련/테스트 세트로 결정 트리 모델 훈련하고 성능 평가하기**

```python
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(train_input, train_target)

print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))
```

> 0.8454877814123533
> 0.8415384615384616

&rarr; 훈련/테스트 세트의 점수가 전처리한 세트의 결과와 동일

**2. 전처리하지 않은 모델 그리기**

```python
plt.figure(figsize=(20,15))
plot_tree(dt, filled=True, feature_names=['alcohol', 'sugar', 'pH'])
plt.show()
```

<img width="665" alt="image" src="https://github.com/user-attachments/assets/579ac555-e7c7-4c59-9cfb-f2df09681d5e">

&rarr; 특성값이 원래의 스케일대로 나타나서 이해하기 쉬움
ex) sugar <= 4.325

**3. 특성 중요도 출력하기**

```python
print(dt.feature_importances_)
```

> [0.12345626 0.86862934 0.0079144 ]

- **중요도**
: 결정 트리에 사용된 특성이 불순도를 감소하는데 기여한 정도
    - \sum (각 노드의 정보 이득) x (전체 샘플에 대한 비율)

## **5-2 교차 검증과 그리드 서치**

### **검증 세트**

: 하이퍼파라미터 튜닝을 위해 모델을 평가할 떄, 테스트 세트를 사용하지 않기 위해 훈련 세트에서 떼어낸 데이터 세트

결정 트리는 테스트해봐야 할 매개변수가 많음(하이퍼파라미터 튜닝)
&rarr; 계속 테스트 세트로 모델 성능을 평가하면 점점 모델이 테스트 세트에 맞춰짐
&rarr; 테스트 세트 사용x, 훈련 세트의 일부분을 검증 세트로 뗴어내기!

<img width="275" alt="image" src="https://github.com/user-attachments/assets/cafdb7f1-294d-4a87-abe2-3f5af37f9646">

**1. 검증 세트 만들기**

```python
import pandas as pd

wine = pd.read_csv('https://bit.ly/wine_csv_data')
data = wine[['alcohol', 'sugar', 'pH']].to_numpy()
target = wine['class'].to_numpy()
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(
    data, target, test_size=0.2, random_state=42)

sub_input, val_input, sub_target, val_target = train_test_split(
    train_input, train_target, test_size=0.2, random_state=42)
```

**2. 훈련 세트와 검증 세트로 모델 훈련하고 성능 평가하기**

```python
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)

print(dt.score(sub_input, sub_target))
print(dt.score(val_input, val_target))
```

> 0.9971133028626413
> 0.864423076923077

&rarr; 과대적합

### **교차검증**

: 훈련 세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델 훈련 &rarr; 모든 폴드에 대해 검증 점수를 얻어 평균

검증 세트를 만들면 훈련 세트가 줄어듦
&rarr; 훈련 세트가 클수록 좋은 모델이지만 검증 세트가 작으면 검증 점수가 불안정해짐
&rarr; 안정적인 검증 점수를 얻고 훈련 세트를 크게 유지하기 위해 교차검증!
&rarr; 폴드 수가 많아질수록 훈련 세트로 사용할 수 있는 데이터의 크기&uarr;

<img width="366" alt="image" src="https://github.com/user-attachments/assets/ec41b00c-38ea-4cf4-bd78-90c3c7a66be9">
&rarr; 3-폴드 교차 검증

**1. 교차 검증하여 검증 폴드 각각의 점수 출력하기**

```python
from sklearn.model_selection import cross_validate

scores = cross_validate(dt, train_input, train_target)
print(scores)
```
> {'fit_time': array([0.00931716, 0.00749564, 0.00773239, 0.00731683, 0.00710797]), 'score_time': array([0.00109315, 0.00111032, 0.00101209, 0.00106931, 0.00115085]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}
- **cross_validate()**
: 교차 검증 함수
    - 첫번째 매개변수(`dt`): 평가할 모델 객체
    - 두번째, 세번째 매개변수(`train_input, train_target`): 훈련 세트 전체
    - `scoring` 매개변수: 검증에 사용할 평가 지표 지정
        - 회귀에서의 기본값은 'r2'
        - 분류에서의 기본값은 'accuracy'
    - `cv` 매개변수: 폴드 수, 스플리터 객체 지정
        - 기본값은 5
        - 회귀 &rarr; KFold()
        - 분류 &rarr; StratifiedKFold()
    - `n_jobs` 매개변수: 교차검증을 수행할 때 사용할 CPU 코어 수 지정
        - 기본값은 1 &rarr;하나의 코어 사용
        - -1 &rarr; 모든 코어 사용
    - `return_train_score` 매개변수
        - 기본값은 False
        - True &rarr; 훈련 세트의 점수도 반환
    - 출력 결과
        : `fit_time`,`score_time`,`test_score`키를 가진 딕셔너리
        - `fit_time`,`score_time`: 모델을 훈련하는 시간과 검증하는 시간
        - `test_score`: 검증 폴드 각각의 점수

**2. 검증 폴드 각각의 점수 평균하기**

```python
import numpy as np

print(np.mean(scores['test_score']))
```

> 0.855300214703487

앞서 `train_test_split()으로 전체 데이터를 섞었기 떄문에 다시 섞을 필요가 x
but 원래는 교차 검증 시 훈련 세트를 섞으려면 splitter를 지정해야 함

**1. splitter 지정하여 데이터를 섞은 후 교차 검증 수행하기**

```python
from sklearn.model_selection import StratifiedKFold

scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
```

> 0.855300214703487

`cv`의 기본값은 5인데 10-폴드 교차 검증을 수행하고 싶다면 

**1. 10-폴드 교차 검증 수행하기**

```python
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
```

> 0.8574181117533719

### **하이퍼파라미터 튜닝**

한 매개변수의 최적값을 찾고 다른 매개변수의 최적값을 찾는 것x
두 매개변수를 동시에 바꿔가며 최적값 찾는 것o

&rarr; Grid Search

- **GridSearchCV()**
: 하이퍼파라미터 탐색과 교차 검증을 한번에 수행
1) 탐색할 매개변수를 나열하면 교차 검증 수행
2) 가장 좋은 검증 점수의 매개변수 조합 선택
3) 최상의 모델을 찾은 후 훈련 세트 전체로 최종 모델 훈련
    - 첫번째 매개변수: 그리드 서치를 수행할 모델 객체 전달
    - 두번째 매개변수: 탐색할 모델의 매개변수와 값 전달
    - `scoring`,`cv`,`n_jobs`,`return_train_score` 매개변수는 `cross_validate()`와 동일

**1. 탐색할 매개변수와 탐색할 값 딕셔너리로 만들기**

```python
from sklearn.model_selection import GridSearchCV

params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}
```

**2. 그리드 서치 객체 만들기**

```python
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
```

**3. gs 객체 훈련하기**

```python
gs.fit(train_input, train_target)
```

&rarr; 'min_impurity_decrease'로 시도하는 값 5개 x 기본 폴드 개수 5개 = 25개의 모델 훈련

**4. 최적의 매개변수 조합이 있는 모델의 성능 평가하기**

```python
dt = gs.best_estimator_
print(dt.score(train_input, train_target))
```

> 0.9615162593804117

- **best_estimator_**
: 25개의 모델 중 검증 점수가 가장 놓은 모델의 매개변수 조합으로 전체 훈련 세트에서 자동으로 다시 훈련된 모델

**5. 최적의 매개변수 출력하기**

```python




    
